<!doctype html>
<html lang="en">

<head>
<meta charset="utf-8">

<title>Deep Learning Course, Chapter 5</title>

<meta name="description" content="Deep Learning Course, Hakim Sabzevari University, Department of Computer Science">
<meta name="author" content="Mahmood Amintoosi">

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

<meta name="viewport" content="width=device-width, initial-scale=1.0">

<link rel="stylesheet" href="../../css/reset.css">
<link rel="stylesheet" href="../../css/reveal.css">
<link rel="stylesheet" href="../../css/theme/serif.css" id="theme">

<!-- Theme used for syntax highlighting of code -->
<link rel="stylesheet" href="../../lib/css/monokai.css">

<!-- Printing and PDF exports -->
<script>
var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /print-pdf/gi ) ? '../../css/print/pdf.css' : '../../css/print/paper.css';
document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>

<!--[if lt IE 9]>
<script src="../../lib/js/html5shiv.js"></script>
<![endif]-->
</head>

<body>

<div class="reveal">

<!-- Any section element inside of this container is displayed as a slide -->
<div class="slides">
<!--
<section>
	<h1>Reveal.js</h1>
	<h3>The HTML Presentation Framework</h3>
	<p>
		<small>Created by <a href="http://hakim.se">Hakim El Hattab</a> and <a href="https://github.com/hakimel/reveal.js/graphs/contributors">contributors</a></small>
	</p>
</section>
<section id="themes">
	<h2>Themes</h2>
	<p>
		reveal.js comes with a few themes built in: <br>
		<!-- Hacks to swap themes after the page has loaded. Not flexible and only intended for the reveal.js demo deck. 
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/black.css'); return false;">Black (default)</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/white.css'); return false;">White</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/league.css'); return false;">League</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/sky.css'); return false;">Sky</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/beige.css'); return false;">Beige</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/simple.css'); return false;">Simple</a> <br>
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/serif.css'); return false;">Serif</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/blood.css'); return false;">Blood</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/night.css'); return false;">Night</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/moon.css'); return false;">Moon</a> -
		<a href="#" onclick="document.getElementById('theme').setAttribute('href','../../css/theme/solarized.css'); return false;">Solarized</a>
	</p>
</section> -->
<section>
 <h2>یادگیری عمیق</h2>
 <h3>Deep Learning</h3>
 <h4>Chapter 5: Deep learning for Computer Vision</h4>
 <h5>Mahmood Amintoosi</h5>
 <p>
  <small><a href="http://https://mamintoosi-cs.github.io/">m.amintoosi</a> @ <a href="http://hsu.ac.ir/">hsu.ac.ir</a></small>
 </p>
 <p>
  <small>پاییز ۹۸</small>
 </p>
</section>

<section>
 <h2>Source book</h2>
	Deep Learning with Python, 
	<br>
	<small>
	by: FRANÇOIS CHOLLET
	</small>
	<br>
	<img height="300" src="./images/DeepLearningWithPython-book-cover.jpg" alt="Deep Learning with Python" xstyle="border:none;box-shadow:none">
	<br>
	<small>
	<a href="https://www.manning.com/books/deep-learning-with-python">https://www.manning.com/books/deep-learning-with-python </a>
	<br>
	<a href="https://livebook.manning.com/book/deep-learning-with-python/"> LiveBook</a><br>
	<a href="https://github.com/fchollet/deep-learning-with-python-notebooks"> Github: Jupyter Notebooks </a>
	</small>
</section>

<section>
   <h2>Chapter 5</h2>
   <h3>Deep learning for Computer Vision</h3>
   <p>This chapter covers:</p>
   <ul class="fix-spacing">
	  <li>Understanding convolutional neural networks
</li><li> Using data augmentation to mitigate overfitting
</li><li> Using a pretrained convnet to do feature
extraction
</li><li> Fine-tuning a pretrained convnet
</li><li> Visualizing what convnets learn and how they
make classification decisions</li>
   </ul>
</section>


<section>
	<section>
	<h3>Understanding convolutional neural networks</h3>
		<ol>
		<li><a href="http://deeplearning.net/software/theano_versions/0.9.X/tutorial/conv_arithmetic.html">Convolution arithmetic tutorial</a>
		</li>
		<li><a href="https://mlblr.com/includes/mlai/index.html#ml-amp-ai"> Machine Learning and AI - Bangalore Chapter</a></li>
		<li><a href="https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889"> Counting No. of Parameters in Deep Learning Models by Hand</a></li>
		</ol> 
	</section>
	<section data-background-iframe="http://deeplearning.net/software/theano_versions/0.9.X/tutorial/conv_arithmetic.html#" data-background-interactive>
	</section>	
	
	<section data-background-iframe="https://mlblr.com/includes/mlai/index.html#ml-amp-ai" data-background-interactive>
	</section>	
</section>

<section>
	<section>
		<h3>Classification with CNNs</h3>
		<ol>
			<li>English Digit Classification</li>
			<li>Persian Digit Classification</li>
			<li>Classifying Cats vs Dogs</li>
		</ol> 	
	</section>
	<section>
		 <code>5.1 - Introduction to convnets</code>
		 <br>
		 MNIST Classification (Included with Keras)
		 <br> Overall Model:
		 <br>
		 <img src="images/digitCNN.jpeg">
	</section>	
	<section>
		 <code>5.1 - Introduction to convnets</code>
		 <br>
		 MNIST Classification, TensorFlow Code
		 <pre>
		 <code class="hljs" data-trim>
import keras
from keras import layers
from keras import models

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))
		 </code>
		 </pre>	
	</section>	
	<section>
		 <code>5.1 - Introduction to convnets</code>
		 <br>
		 Number of Parameters
		 <pre>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     
_________________________________________________________________
flatten_1 (Flatten)          (None, 576)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 64)                36928     
_________________________________________________________________
dense_2 (Dense)              (None, 10)                650       
=================================================================
Total params: 93,322
		 </pre>	
	</section>	
</section>
<section>	
	<section>
		<xsmall>
		<a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53"> 
		Overall Architecture of a sample CNN</a></xsmall><br>
		<img src="images/cnn_overall.jpeg">
		<small>
		More about architecture and number of parameters:
		<ul>
			<li><a href="https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889"> Counting No. of Parameters in Deep Learning Models by Hand </a>			</li>
			<li> 
			<a href="https://medium.com/@iamvarman/how-to-calculate-the-number-of-parameters-in-the-cnn-5bd55364d7ca"> 
			How to calculate the number of parameters in the CNN? </a> </li>
			<!--
Convolutional Layer : Consider a convolutional layer which takes “l” feature maps as the input and has “k” feature maps as output. The filter size is “n*m”.
Here the input has l=32 feature maps as inputs, k=64 feature maps as outputs and filter size is n=3 and m=3. It is important to understand, that we don’t simply have a 3*3 filter, but actually, we have 3*3*32 filter, as our input has 32 dimensions. And as an output from first conv layer, we learn 64 different 3*3*32 filters which total weights is “n*m*k*l”. Then there is a term called bias for each feature map. So, the total number of parameters are “(n*m*l+1)*k”.			
			-->
		</ul>
		</small>
	</section>	
	<section>
		<img src="images/cnn_1_3.png" width="700">
		<small>Source:<a href="https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889"> 
		Counting No. of Parameters in Deep Learning Models by Hand</a></small>
	</section>	
	<section>
		<img src="images/cnn_3_1.png" width="700">
		<small>Source:<a href="https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889"> 
		Counting No. of Parameters in Deep Learning Models by Hand</a></small>
	</section>	
	<section>
		<img src="images/cnn_2_3.png" width="500">
		<small>Source:<a href="https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889"> 
		Counting No. of Parameters in Deep Learning Models by Hand</a></small>
	</section>	
	
	<section>
		 <code> -- </code>
		 <br>
		 Persian Digits Classification (Not included with Keras)
		 <pre>
		 <code class="hljs" data-trim>
import keras
from keras import layers
from keras import models

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))	
		 </code>
		 </pre>	
	</section>	
</section>	
<section>
	<section>
		<code>5.2 - Using convnets with small datasets</code>
		<br>
		Classify Dogs vs Cats (Not included with Keras)
		<br>
		<img src="images/Fig5.8-DogsCats.jpg">
		<img src="images/image-classification-cat-1.jpg" class="fragment">
	</section>	
	<section>
		 <code>5.2 - Using convnets with small datasets</code>
		 <br>
		 Classify Dogs vs Cats (Building from scrach)
		 <ul>
			<li>Download Images from <a href="www.kaggle.com/c/dogs-vs-cats/data"> Kaggle </a>
			</li>
			<li>
				Download Images from <a href="https://www.floydhub.com/api/v1/resources/MmV389WwjuivQhKXoA9GaR?content=true&download=true&rename=fastai-datasets-cats-vs-dogs-2">
				fastai </a> 845MB, (need some manipulation)
			</li>
		</ul>	
	</section>		
	<section>
		 <code>5.2 - Using convnets with small datasets</code>
		 <br>
		 Classify Dogs vs Cats (Building from scrach)
		 <pre>
		 <code class="hljs" data-trim>
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu',
                        input_shape=(150, 150, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))			
		 </code>
		 </pre>	
	</section>		
	<section>
	</section>		
</section>

<section>	
	<section>
There are various architectures of CNNs available<br>
LeNet, AlexNet, VGGNet, GoogLeNet, ResNet, ZFNet <br>
<img src="images/acc_vs_net_vs_ops.svg">
	</section>	
	<section>
		<a href="https://neurohive.io/en/popular-networks/vgg16/"> 
		VGG16 Architecture </a><br>
		<img src="images/vgg16.png">
	</section>	
	<section data-background="images/nvidia-gtx-titan-black.jpg" data-background-opacity=.2>
		VGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper “Very Deep Convolutional Networks for Large-Scale Image Recognition”. The model achieves 92.7% top-5 test accuracy in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes. VGG16 was trained for weeks and was using NVIDIA Titan Black GPU’s.
	</section>	
</section>

<section>	
	<section>
		ML vs DL <br>
		<img src="images/MLvsDL_ces2016.png">
	</section>	
	<section>
		Some Outputs <br>
		<img src="images/out_01.jpg">
		<img src="images/yolo_pred.jpg">
	</section>	
	<section>
		Our Outputs <br>
		<img src="images/1_2 (9).jpg">
		<img src="images/1_5 (12).jpg">
	</section>	
	<section>
		Our Outputs <br>
		<img src="images/1_4 (28).jpg">
	</section>	
</section>



<section>
 <h3>- Questions? -</h3>
 <br>
 m.amintoosi @ gmail.com
 <br>
 <p>webpage : <a href="http://mamintoosi.ir/">http://mamintoosi.ir</a></p>
 <p>webpage in github : <a href="https://mamintoosi-cs.github.io/">http://mamintoosi-cs.github.io</a></p>
 <p>github : <a href="https://github.com/mamintoosi">mamintoosi</a></p>
 <hr>
<!-- <small>
 <p> مطالب و سبک اسلاید برگرفته از 
	<a href="https://github.com/mdda/deep-learning-workshop"> Martin Andrews </a>
	و
	<a href="https://hameds.github.io/slides/"> سعیدی‌فرد </a>
 </p>
 </small>
--> 
</section>	


</div>

</div>

<script src="../../js/reveal.js"></script>

<script>

// More info https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({
	controls: true,
	progress: true,
	center: true,
	hash: true,
	slideNumber: true,

	transition: 'slide', // none/fade/slide/convex/concave/zoom

	// More info https://github.com/hakimel/reveal.js#dependencies
	dependencies: [
		{ src: '../../plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
		{ src: '../../plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
		{ src: '../../plugin/highlight/highlight.js', async: true },
		{ src: '../../plugin/search/search.js', async: true },
		{ src: '../../plugin/zoom-js/zoom.js', async: true },
		{ src: '../../plugin/notes/notes.js', async: true }
	]
});

</script>

</body>
</html>
